{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6728cf5",
   "metadata": {},
   "source": [
    "# Build a Regression Model in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dc61ae",
   "metadata": {},
   "source": [
    "### Table Of Contents"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2800c76f",
   "metadata": {},
   "source": [
    "1.Some useful functions\n",
    "2.Loading input corpus\n",
    "3.Reviewing the loaded data\n",
    "4.Normalizing input data\n",
    "5.Splitting corpus into traning set and testing set\n",
    "6.A - Experiment with a baseline model\n",
    "7.B - Experiment with Normalized Data\n",
    "8.C. Increate the number of epochs\n",
    "9.D. Increase the number of hidden layers\n",
    "10.Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae6647",
   "metadata": {},
   "source": [
    "#### The dataset is about the compressive strength of different samples of concrete based on the volumes of the different ingredients that were used to make them. Ingredients include:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d23121e",
   "metadata": {},
   "source": [
    "# 1. Cement\n",
    "\n",
    "2. Blast Furnace Slag\n",
    "\n",
    "3. Fly Ash\n",
    "\n",
    "4. Water\n",
    "\n",
    "5. Superplasticizer\n",
    "\n",
    "6. Coarse Aggregate\n",
    "\n",
    "7. Fine Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f345179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f785bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_NAME_CEMENT = \"Cement\"\n",
    "COL_NAME_BLAST_FURNACE_SLAG = \"Blast Furnace Slag\"\n",
    "COL_NAME_FLY_ASH = \"Fly Ash\"\n",
    "COL_NAME_WATER = \"Water\"\n",
    "COL_NAME_SUPERPLASTICIZER = \"Superplasticizer\"\n",
    "COL_NAME_COARSE_AGGREGATE = \"Coarse Aggregate\"\n",
    "COL_NAME_FINE_AGGREGATE = \"Fine Aggregate\"\n",
    "COL_NAME_AGE = \"Age\"\n",
    "COL_NAME_STRENGTH = \"Strength\"\n",
    "\n",
    "COL_NAME_EXPERIMENT = \"Experiment\"\n",
    "COL_NAME_MSE = \"Mean MSE\"\n",
    "COL_NAME_RMSE = \"Std Deviation MSE\"\n",
    "\n",
    "# This dataframe contains three columns: \n",
    "# name_of_experiments, mse, rmse\n",
    "header_of_df_mse_and_rmse = [COL_NAME_EXPERIMENT, COL_NAME_MSE, COL_NAME_RMSE]\n",
    "df_mse_and_rmse = pd.DataFrame(columns=header_of_df_mse_and_rmse, data=[])\n",
    "\n",
    "\n",
    "def get_round(score, num_of_digits=2):\n",
    "    \"\"\"Get round with given number of decimal digits \n",
    "    \"\"\"\n",
    "    return round(score, num_of_digits)\n",
    "\n",
    "\n",
    "def get_mean(list_of_mse_scores):\n",
    "    \"\"\"Get mean\n",
    "    \"\"\"\n",
    "    if list_of_mse_scores:\n",
    "        return get_round(np.mean(list_of_mse_scores))\n",
    "    return None\n",
    "\n",
    "def get_standard_deviation(list_of_mse_scores):\n",
    "    \"\"\"Get standard deviation\n",
    "    \"\"\"\n",
    "    if list_of_mse_scores:\n",
    "        return get_round(np.std(list_of_mse_scores))\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_model_with_one_hidden_layer(num_of_features=3):\n",
    "    \"\"\" Building baseline model that contains:\n",
    "\n",
    "    + One hidden layer of 10 nodes, and a ReLU activation function.\n",
    "    + Use the adam optimizer and the mean squared error as the loss function.\n",
    "    \"\"\"    \n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(10, activation=\"relu\", input_shape=(num_of_features,)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_with_three_hidden_layers(num_of_features=3):\n",
    "    \"\"\" Building model that contains:\n",
    "    \n",
    "     + Three hidden layers, each of 10 nodes and ReLU activation function.    \n",
    "    + Use the adam optimizer and the mean squared error as the loss function.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(10, activation=\"relu\", input_shape=(num_of_features,)))\n",
    "    model.add(Dense(10, activation=\"relu\"))\n",
    "    model.add(Dense(10, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_mean_squared_error(compiled_model, X, y, epochs=50, verbose=1):\n",
    "    \"\"\"Get report (dataframe) of two metrics: \n",
    "    The mean and the standard deviation of the mean squared errors\n",
    "    \"\"\"   \n",
    "    \n",
    "    # 1. Randomly split the data into a training and test sets by holding 30% \n",
    "    # of the data for testing. You can use the train_test_split helper function \n",
    "    # from Scikit-learn.    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=24)   \n",
    "    print(\"Training set: \", X_train.shape, y_train.shape)\n",
    "    print(\"Testing set: \", X_test.shape, y_test.shape)\n",
    "    \n",
    "    \n",
    "    # 2. Train the model on the training data using 50 epochs.\n",
    "    # Note that: given model which is compiled\n",
    "    # Fit the built model with training set\n",
    "    model.fit(X_train, y_train, epochs=epochs, verbose=verbose) \n",
    "    # 3. Evaluate the model on the test data and compute the mean squared error \n",
    "    # between the predicted concrete strength and the actual concrete strength. \n",
    "    # You can use the mean_squared_error function from Scikit-learn.    \n",
    "    y_hat = model.predict(X_test)    \n",
    "    mse = mean_squared_error(y_test, y_hat)\n",
    "    \n",
    "    # Return the mean squared error\n",
    "    return mse\n",
    "\n",
    "\n",
    "def get_mean_and_std_of_mse(df_X, \n",
    "                            df_y, \n",
    "                            compiled_model,                \n",
    "                            max_iteration=50, \n",
    "                            epochs=50, \n",
    "                            verbose=0):\n",
    "    \"\"\"Generate the mean and the standard deviation of the mean squared errors \n",
    "    \"\"\"\n",
    "    # Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.    \n",
    "    list_of_mean_squared_errors = []\n",
    "    for i in range(max_iteration):\n",
    "        start_time = time.time()\n",
    "        print(\"-\" * 36)\n",
    "        print(\"Processing current number of iteration : {}\".format(i+1))        \n",
    "        mse = get_mean_squared_error(compiled_model, df_X, df_y, epochs=epochs, verbose=verbose)\n",
    "        list_of_mean_squared_errors.append(mse)\n",
    "        print(\"Duration (seconds): {}\".format(time.time()-start_time))\n",
    "    # end for\n",
    "\n",
    "    print(\"Finished - {} times.\\nAnd the list of mean squared errors : {}\".format(max_iteration,\n",
    "                                                                              \n",
    "                                                                              list_of_mean_squared_errors))\n",
    "\n",
    "    mean_mse = get_mean(list_of_mean_squared_errors)\n",
    "    std_mse = get_standard_deviation(list_of_mean_squared_errors)\n",
    "\n",
    "    print(\"-\" * 72)\n",
    "    print(\"The mean and the standard deviation of the mean squared errors are: {} and {}, respectively\".format(\n",
    "           mean_mse, std_mse))\n",
    "    \n",
    "    return mean_mse, std_mse\n",
    "\n",
    "\n",
    "def get_report(name_of_experiment, mean_mse, std_mse):\n",
    "    \"\"\"Get report (dataframe) of two metrics: \n",
    "    The mean and the standard deviation of the mean squared errors\n",
    "    \"\"\"\n",
    "    values = [[name_of_experiment, mean_mse, std_mse]]\n",
    "\n",
    "    return pd.DataFrame(columns=header_of_df_mse_and_rmse, data=values)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85bbff",
   "metadata": {},
   "source": [
    "# Loading input corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a06032",
   "metadata": {},
   "source": [
    "Let's assign the path of input corpus. Because we re-use after dowloading the input corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d1d7ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9b15ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4039d3",
   "metadata": {},
   "source": [
    "Let's read input data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1e0df63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d6c014e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
       "       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6772caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bdbd38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Cement              1030 non-null   float64\n",
      " 1   Blast Furnace Slag  1030 non-null   float64\n",
      " 2   Fly Ash             1030 non-null   float64\n",
      " 3   Water               1030 non-null   float64\n",
      " 4   Superplasticizer    1030 non-null   float64\n",
      " 5   Coarse Aggregate    1030 non-null   float64\n",
      " 6   Fine Aggregate      1030 non-null   float64\n",
      " 7   Age                 1030 non-null   int64  \n",
      " 8   Strength            1030 non-null   float64\n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 72.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91162cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2a7ae",
   "metadata": {},
   "source": [
    "So the first concrete sample has \"540\" cubic meter of cement, \"0\" cubic meter of blast furnace slag, \"0\" cubic meter of fly ash, \"162\" cubic meter of water, \"2.5\" cubic meter of superplaticizer, \"1040\" cubic meter of coarse aggregate, \"676\" cubic meter of fine aggregate. Such a concrete mix which is \"28\" days old, has a compressive strength of \"79.99\" MPa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4fad8212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(row, column) = (1030, 9)\n"
     ]
    }
   ],
   "source": [
    "print(\"(row, column) = {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd2b247",
   "metadata": {},
   "source": [
    "So, there are approximately 1000 samples to train our model on when splitting with 30% for the data of testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4dd227",
   "metadata": {},
   "source": [
    "Let's check the data for any missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "85b47ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d803d9",
   "metadata": {},
   "source": [
    "As you see, the above input corpus look pretty good to train the model. However, we could use the normalization technique to normalize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237924fa",
   "metadata": {},
   "source": [
    "# Normalizing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07e05121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
       "       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_column_names = df.columns\n",
    "list_of_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1c5d8",
   "metadata": {},
   "source": [
    "## Splitting into predictors and target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0bd851",
   "metadata": {},
   "source": [
    "Filtering the list of column names of dataframe predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e09359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_col_names_predictors = [x for x in list_of_column_names \n",
    "                                if x != COL_NAME_STRENGTH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e8bc723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cement',\n",
       " 'Blast Furnace Slag',\n",
       " 'Fly Ash',\n",
       " 'Water',\n",
       " 'Superplasticizer',\n",
       " 'Coarse Aggregate',\n",
       " 'Fine Aggregate',\n",
       " 'Age']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_col_names_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "452d5641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictors = df[list_of_col_names_predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5c9f7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target = df[[COL_NAME_STRENGTH]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eab1e1",
   "metadata": {},
   "source": [
    "Reviewing the data in two dataframes: predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5bd4201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictors.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4ba0aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Strength\n",
       "0     79.99\n",
       "1     61.89\n",
       "2     40.27"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44485e96",
   "metadata": {},
   "source": [
    "# Applying normalization method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542a6fff",
   "metadata": {},
   "source": [
    "Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e22067e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictors_norm = (df_predictors - df_predictors.mean())/df_predictors.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5dfab193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictors_norm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6534a2e5",
   "metadata": {},
   "source": [
    "# A - Experiment with a baseline model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "003812bd",
   "metadata": {},
   "source": [
    "Use the Keras library to build a neural network with the following:\n",
    "\n",
    "One hidden layer of 10 nodes, and a ReLU activation function\n",
    "\n",
    "Use the adam optimizer and the mean squared error as the loss function.\n",
    "\n",
    "Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split helper function from Scikit-learn.\n",
    "\n",
    "Train the model on the training data using 50 epochs.\n",
    "\n",
    "Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n",
    "\n",
    "Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors.\n",
    "\n",
    "Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6eb9d0",
   "metadata": {},
   "source": [
    "## Building and Training with the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9ace79a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for input layer :  8\n"
     ]
    }
   ],
   "source": [
    "num_of_features = len(df.columns) - 1\n",
    "print(\"Number of features for input layer : \", num_of_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "56617ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Processing current number of iteration : 1\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.028974533081055\n",
      "------------------------------------\n",
      "Processing current number of iteration : 2\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 5.534287214279175\n",
      "------------------------------------\n",
      "Processing current number of iteration : 3\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.583523273468018\n",
      "------------------------------------\n",
      "Processing current number of iteration : 4\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.706511497497559\n",
      "------------------------------------\n",
      "Processing current number of iteration : 5\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.510452508926392\n",
      "------------------------------------\n",
      "Processing current number of iteration : 6\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 5.625430583953857\n",
      "------------------------------------\n",
      "Processing current number of iteration : 7\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 5.629841566085815\n",
      "------------------------------------\n",
      "Processing current number of iteration : 8\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.4832940101623535\n",
      "------------------------------------\n",
      "Processing current number of iteration : 9\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.557046413421631\n",
      "------------------------------------\n",
      "Processing current number of iteration : 10\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.508753776550293\n",
      "------------------------------------\n",
      "Processing current number of iteration : 11\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.534101247787476\n",
      "------------------------------------\n",
      "Processing current number of iteration : 12\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.521157741546631\n",
      "------------------------------------\n",
      "Processing current number of iteration : 13\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.512004375457764\n",
      "------------------------------------\n",
      "Processing current number of iteration : 14\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.576978445053101\n",
      "------------------------------------\n",
      "Processing current number of iteration : 15\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.5810041427612305\n",
      "------------------------------------\n",
      "Processing current number of iteration : 16\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.424685478210449\n",
      "------------------------------------\n",
      "Processing current number of iteration : 17\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.52573299407959\n",
      "------------------------------------\n",
      "Processing current number of iteration : 18\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 10.92298173904419\n",
      "------------------------------------\n",
      "Processing current number of iteration : 19\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.323466062545776\n",
      "------------------------------------\n",
      "Processing current number of iteration : 20\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.548979997634888\n",
      "------------------------------------\n",
      "Processing current number of iteration : 21\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.568052530288696\n",
      "------------------------------------\n",
      "Processing current number of iteration : 22\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.567830562591553\n",
      "------------------------------------\n",
      "Processing current number of iteration : 23\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.489208459854126\n",
      "------------------------------------\n",
      "Processing current number of iteration : 24\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.651114463806152\n",
      "------------------------------------\n",
      "Processing current number of iteration : 25\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.4990074634552\n",
      "------------------------------------\n",
      "Processing current number of iteration : 26\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.6307549476623535\n",
      "------------------------------------\n",
      "Processing current number of iteration : 27\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.572680473327637\n",
      "------------------------------------\n",
      "Processing current number of iteration : 28\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.139601469039917\n",
      "------------------------------------\n",
      "Processing current number of iteration : 29\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.160126209259033\n",
      "------------------------------------\n",
      "Processing current number of iteration : 30\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.6032562255859375\n",
      "------------------------------------\n",
      "Processing current number of iteration : 31\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.557873964309692\n",
      "------------------------------------\n",
      "Processing current number of iteration : 32\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.644931316375732\n",
      "------------------------------------\n",
      "Processing current number of iteration : 33\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.556080102920532\n",
      "------------------------------------\n",
      "Processing current number of iteration : 34\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.558547735214233\n",
      "------------------------------------\n",
      "Processing current number of iteration : 35\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.504798889160156\n",
      "------------------------------------\n",
      "Processing current number of iteration : 36\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.5306479930877686\n",
      "------------------------------------\n",
      "Processing current number of iteration : 37\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.607993841171265\n",
      "------------------------------------\n",
      "Processing current number of iteration : 38\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.534236907958984\n",
      "------------------------------------\n",
      "Processing current number of iteration : 39\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.477440357208252\n",
      "------------------------------------\n",
      "Processing current number of iteration : 40\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.480641841888428\n",
      "------------------------------------\n",
      "Processing current number of iteration : 41\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 5.494004964828491\n",
      "------------------------------------\n",
      "Processing current number of iteration : 42\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.5328264236450195\n",
      "------------------------------------\n",
      "Processing current number of iteration : 43\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.526930570602417\n",
      "------------------------------------\n",
      "Processing current number of iteration : 44\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.509094476699829\n",
      "------------------------------------\n",
      "Processing current number of iteration : 45\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.8880040645599365\n",
      "------------------------------------\n",
      "Processing current number of iteration : 46\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.577866792678833\n",
      "------------------------------------\n",
      "Processing current number of iteration : 47\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.550005674362183\n",
      "------------------------------------\n",
      "Processing current number of iteration : 48\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.562488794326782\n",
      "------------------------------------\n",
      "Processing current number of iteration : 49\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.575775384902954\n",
      "------------------------------------\n",
      "Processing current number of iteration : 50\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.570804595947266\n",
      "Finished - 50 times.\n",
      "And the list of mean squared errors : [248.35190940128305, 107.03955614177893, 104.19850334127861, 95.89511703282422, 90.76088621307555, 95.25793407742741, 80.53176294615854, 75.01516203573213, 71.89630573467292, 68.28930372478595, 65.75702618286445, 59.99601361225223, 55.070597205882635, 57.11422694031314, 55.51954382337872, 51.07579635881915, 55.254394129259396, 50.19392758142385, 49.46034587792793, 49.81046636625548, 49.99606495918348, 49.333805402445265, 51.67084766305178, 49.265152042395755, 50.6116956920577, 57.26176199215654, 49.26981200880011, 49.215194509462535, 49.20992726077399, 49.142720145631806, 49.377766996875025, 50.87177583000761, 50.802728841302304, 49.28616136995086, 49.21726179478983, 49.856656797571304, 49.56735611078238, 48.928206641715434, 48.76833079186824, 48.22020665388318, 47.446924198317745, 47.13426648699627, 46.99953935942715, 46.41898863596195, 45.980974961734695, 45.5164264338235, 45.474955971800874, 45.144214519391916, 44.38098910011143, 44.07872567216438]\n",
      "------------------------------------------------------------------------\n",
      "The mean and the standard deviation of the mean squared errors are: 60.9 and 31.15, respectively\n"
     ]
    }
   ],
   "source": [
    "max_iteration = 50\n",
    "epochs = 50\n",
    "verbose = 0\n",
    "\n",
    "# Get the compiled model\n",
    "model = build_model_with_one_hidden_layer(num_of_features=num_of_features)\n",
    "\n",
    "mean_mse, std_mse = get_mean_and_std_of_mse(df_predictors, \n",
    "                                            df_target, \n",
    "                                            model, \n",
    "                                            max_iteration=max_iteration, \n",
    "                                            epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c76ee3",
   "metadata": {},
   "source": [
    "## Report the mean and the standard deviation of the mean squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a5426b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline-Raw (50 epochs)</td>\n",
       "      <td>60.9</td>\n",
       "      <td>31.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Experiment  Mean MSE  Std Deviation MSE\n",
       "0  Baseline-Raw (50 epochs)      60.9              31.15"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_experiment = \"Baseline-Raw (50 epochs)\"\n",
    "\n",
    "# Report the mean and the standard deviation of the mean squared errors\n",
    "df_result_baseline = get_report(name_of_experiment, mean_mse, std_mse)\n",
    "df_result_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fea906c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline-Raw (50 epochs)</td>\n",
       "      <td>60.9</td>\n",
       "      <td>31.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Experiment  Mean MSE  Std Deviation MSE\n",
       "0  Baseline-Raw (50 epochs)      60.9              31.15"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat baseline dataframe into result\n",
    "df_mse_and_rmse = pd.concat([df_mse_and_rmse, df_result_baseline], axis=0)\n",
    "\n",
    "# Review the result dataframe\n",
    "df_mse_and_rmse.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b268c2ff",
   "metadata": {},
   "source": [
    "# B - Experiment with Normalized Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932305ea",
   "metadata": {},
   "source": [
    "Repeat Part A but use a normalized version of the data. Recall that one way to normalize the data is by subtracting the mean from the individual predictors and dividing by the standard deviation.\n",
    "\n",
    "How does the mean of the mean squared errors compare to that from Step A?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b631a",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0ca501",
   "metadata": {},
   "source": [
    "by substracting the mean and dividing by the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27270351",
   "metadata": {},
   "source": [
    "## Before normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6366370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictors.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b14c0c",
   "metadata": {},
   "source": [
    "# After normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c0df958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictors_norm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831141e4",
   "metadata": {},
   "source": [
    "## Building and Training with the baseline model after normalizing the data with 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "217272c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Processing current number of iteration : 1\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 8.05424427986145\n",
      "------------------------------------\n",
      "Processing current number of iteration : 2\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 5.512316942214966\n",
      "------------------------------------\n",
      "Processing current number of iteration : 3\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.534383773803711\n",
      "------------------------------------\n",
      "Processing current number of iteration : 4\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.5043625831604\n",
      "------------------------------------\n",
      "Processing current number of iteration : 5\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.4938740730285645\n",
      "------------------------------------\n",
      "Processing current number of iteration : 6\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 5.5016844272613525\n",
      "------------------------------------\n",
      "Processing current number of iteration : 7\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.664555072784424\n",
      "------------------------------------\n",
      "Processing current number of iteration : 8\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 6.385502338409424\n",
      "------------------------------------\n",
      "Processing current number of iteration : 9\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Duration (seconds): 7.250997543334961\n",
      "------------------------------------\n",
      "Processing current number of iteration : 10\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 7.712976694107056\n",
      "------------------------------------\n",
      "Processing current number of iteration : 11\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.9802234172821045\n",
      "------------------------------------\n",
      "Processing current number of iteration : 12\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.4070048332214355\n",
      "------------------------------------\n",
      "Processing current number of iteration : 13\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.418701887130737\n",
      "------------------------------------\n",
      "Processing current number of iteration : 14\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.506901502609253\n",
      "------------------------------------\n",
      "Processing current number of iteration : 15\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.449933290481567\n",
      "------------------------------------\n",
      "Processing current number of iteration : 16\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.403997182846069\n",
      "------------------------------------\n",
      "Processing current number of iteration : 17\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.4059226512908936\n",
      "------------------------------------\n",
      "Processing current number of iteration : 18\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.4478700160980225\n",
      "------------------------------------\n",
      "Processing current number of iteration : 19\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.437914609909058\n",
      "------------------------------------\n",
      "Processing current number of iteration : 20\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.405082941055298\n",
      "------------------------------------\n",
      "Processing current number of iteration : 21\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.418254613876343\n",
      "------------------------------------\n",
      "Processing current number of iteration : 22\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.416989803314209\n",
      "------------------------------------\n",
      "Processing current number of iteration : 23\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.435048341751099\n",
      "------------------------------------\n",
      "Processing current number of iteration : 24\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.414925575256348\n",
      "------------------------------------\n",
      "Processing current number of iteration : 25\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.768832445144653\n",
      "------------------------------------\n",
      "Processing current number of iteration : 26\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.575350522994995\n",
      "------------------------------------\n",
      "Processing current number of iteration : 27\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.201167106628418\n",
      "------------------------------------\n",
      "Processing current number of iteration : 28\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.560006856918335\n",
      "------------------------------------\n",
      "Processing current number of iteration : 29\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.863337755203247\n",
      "------------------------------------\n",
      "Processing current number of iteration : 30\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.548166990280151\n",
      "------------------------------------\n",
      "Processing current number of iteration : 31\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.765026330947876\n",
      "------------------------------------\n",
      "Processing current number of iteration : 32\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.655321359634399\n",
      "------------------------------------\n",
      "Processing current number of iteration : 33\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.52547550201416\n",
      "------------------------------------\n",
      "Processing current number of iteration : 34\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 5.54312801361084\n",
      "------------------------------------\n",
      "Processing current number of iteration : 35\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.5580315589904785\n",
      "------------------------------------\n",
      "Processing current number of iteration : 36\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.5479371547698975\n",
      "------------------------------------\n",
      "Processing current number of iteration : 37\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.567004442214966\n",
      "------------------------------------\n",
      "Processing current number of iteration : 38\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "Duration (seconds): 5.821974277496338\n",
      "------------------------------------\n",
      "Processing current number of iteration : 39\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.76003360748291\n",
      "------------------------------------\n",
      "Processing current number of iteration : 40\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.554866552352905\n",
      "------------------------------------\n",
      "Processing current number of iteration : 41\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.572798252105713\n",
      "------------------------------------\n",
      "Processing current number of iteration : 42\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "Duration (seconds): 6.612616539001465\n",
      "------------------------------------\n",
      "Processing current number of iteration : 43\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 6.671062469482422\n",
      "------------------------------------\n",
      "Processing current number of iteration : 44\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 6.169467210769653\n",
      "------------------------------------\n",
      "Processing current number of iteration : 45\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.063853025436401\n",
      "------------------------------------\n",
      "Processing current number of iteration : 46\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.565871477127075\n",
      "------------------------------------\n",
      "Processing current number of iteration : 47\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.552377223968506\n",
      "------------------------------------\n",
      "Processing current number of iteration : 48\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.545032978057861\n",
      "------------------------------------\n",
      "Processing current number of iteration : 49\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 5.765165567398071\n",
      "------------------------------------\n",
      "Processing current number of iteration : 50\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.174005508422852\n",
      "Finished - 50 times.\n",
      "And the list of mean squared errors : [268.2949251838623, 147.57320262996117, 108.344239845345, 82.11641928713986, 64.46665188954002, 54.00745326606967, 48.76867857477815, 45.916154964873236, 44.055145805503045, 42.724501408789365, 41.93422060046744, 41.15039639758977, 40.57325432386018, 40.22140958366335, 39.551015186307616, 39.0369323003676, 38.63726257467144, 38.32537774170568, 38.05392874792005, 37.83846559184428, 37.69609547307255, 37.64482279828036, 37.5703794060525, 37.472935578546014, 37.36210452859788, 37.119589308762954, 36.997853210158354, 36.89322063858188, 36.752216439462536, 36.79919504965789, 36.84199415768963, 36.93795921897487, 36.70752252337189, 36.72479160733654, 36.78470477702174, 36.69040039289145, 36.92840707972897, 36.884744145103326, 36.925721272161496, 37.06283078538603, 36.99587207180613, 36.96959110810227, 37.04185211828142, 36.911921553022545, 36.815187082362975, 37.00252769877362, 36.93768726938843, 36.93983400697879, 36.9945547112566, 36.8837958653822]\n",
      "------------------------------------------------------------------------\n",
      "The mean and the standard deviation of the mean squared errors are: 48.24 and 36.87, respectively\n"
     ]
    }
   ],
   "source": [
    "max_iteration = 50\n",
    "epochs = 50\n",
    "verbose = 0\n",
    "\n",
    "# Get the compiled model\n",
    "model = build_model_with_one_hidden_layer(num_of_features=num_of_features)\n",
    "\n",
    "mean_mse, std_mse = get_mean_and_std_of_mse(df_predictors_norm, \n",
    "                                            df_target, \n",
    "                                            model, \n",
    "                                            max_iteration=max_iteration, \n",
    "                                            epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0c2201",
   "metadata": {},
   "source": [
    "### Report the mean and the standard deviation of the mean squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d64df56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normalized-1 Hidden Layers(50 epochs)</td>\n",
       "      <td>48.24</td>\n",
       "      <td>36.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Experiment  Mean MSE  Std Deviation MSE\n",
       "0  Normalized-1 Hidden Layers(50 epochs)     48.24              36.87"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_experiment = \"Normalized-1 Hidden Layers(50 epochs)\"\n",
    "\n",
    "# Report the mean and the standard deviation of the mean squared errors\n",
    "df_result_baseline = get_report(name_of_experiment, mean_mse, std_mse)\n",
    "df_result_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd05543f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline-Raw (50 epochs)</td>\n",
       "      <td>60.90</td>\n",
       "      <td>31.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normalized-1 Hidden Layers(50 epochs)</td>\n",
       "      <td>48.24</td>\n",
       "      <td>36.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Experiment  Mean MSE  Std Deviation MSE\n",
       "0               Baseline-Raw (50 epochs)     60.90              31.15\n",
       "1  Normalized-1 Hidden Layers(50 epochs)     48.24              36.87"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat baseline dataframe into result\n",
    "df_mse_and_rmse = pd.concat([df_mse_and_rmse, df_result_baseline], axis=0)\n",
    "\n",
    "# Review the result dataframe\n",
    "df_mse_and_rmse.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233a6dd",
   "metadata": {},
   "source": [
    "# C. Increate the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fcade7",
   "metadata": {},
   "source": [
    "Repeat Part B but use 100 epochs this time for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26430799",
   "metadata": {},
   "source": [
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945409c",
   "metadata": {},
   "source": [
    "# Building and Training with the baseline model after normalizing the data with 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ce4d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Processing current number of iteration : 1\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Duration (seconds): 11.011007308959961\n",
      "------------------------------------\n",
      "Processing current number of iteration : 2\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 9.673621416091919\n",
      "------------------------------------\n",
      "Processing current number of iteration : 3\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Duration (seconds): 10.909236192703247\n",
      "------------------------------------\n",
      "Processing current number of iteration : 4\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "Duration (seconds): 10.72933578491211\n",
      "------------------------------------\n",
      "Processing current number of iteration : 5\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 13.2069833278656\n",
      "------------------------------------\n",
      "Processing current number of iteration : 6\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 14.702913761138916\n",
      "------------------------------------\n",
      "Processing current number of iteration : 7\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Duration (seconds): 10.583992004394531\n",
      "------------------------------------\n",
      "Processing current number of iteration : 8\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 11.796965837478638\n",
      "------------------------------------\n",
      "Processing current number of iteration : 9\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 21.79952597618103\n",
      "------------------------------------\n",
      "Processing current number of iteration : 10\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Duration (seconds): 9.755256652832031\n",
      "------------------------------------\n",
      "Processing current number of iteration : 11\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 3ms/step\n",
      "Duration (seconds): 5.58245062828064\n",
      "------------------------------------\n",
      "Processing current number of iteration : 12\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.90535831451416\n",
      "------------------------------------\n",
      "Processing current number of iteration : 13\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 13.709012269973755\n",
      "------------------------------------\n",
      "Processing current number of iteration : 14\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Duration (seconds): 10.144752502441406\n",
      "------------------------------------\n",
      "Processing current number of iteration : 15\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Duration (seconds): 5.257061719894409\n",
      "------------------------------------\n",
      "Processing current number of iteration : 16\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 12.813293933868408\n",
      "------------------------------------\n",
      "Processing current number of iteration : 17\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 10ms/step\n",
      "Duration (seconds): 9.06332278251648\n",
      "------------------------------------\n",
      "Processing current number of iteration : 18\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 12.65836787223816\n",
      "------------------------------------\n",
      "Processing current number of iteration : 19\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 8.437128067016602\n",
      "------------------------------------\n",
      "Processing current number of iteration : 20\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 13.162917613983154\n",
      "------------------------------------\n",
      "Processing current number of iteration : 21\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.69832706451416\n",
      "------------------------------------\n",
      "Processing current number of iteration : 22\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.62514615058899\n",
      "------------------------------------\n",
      "Processing current number of iteration : 23\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.54500150680542\n",
      "------------------------------------\n",
      "Processing current number of iteration : 24\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 11.990981340408325\n",
      "------------------------------------\n",
      "Processing current number of iteration : 25\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 15.270076513290405\n",
      "------------------------------------\n",
      "Processing current number of iteration : 26\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "Duration (seconds): 14.515013217926025\n",
      "------------------------------------\n",
      "Processing current number of iteration : 27\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 13.908088684082031\n",
      "------------------------------------\n",
      "Processing current number of iteration : 28\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.263012647628784\n",
      "------------------------------------\n",
      "Processing current number of iteration : 29\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.286832571029663\n",
      "------------------------------------\n",
      "Processing current number of iteration : 30\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 11.539045333862305\n",
      "------------------------------------\n",
      "Processing current number of iteration : 31\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 11.025130987167358\n",
      "------------------------------------\n",
      "Processing current number of iteration : 32\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 13.60307240486145\n",
      "------------------------------------\n",
      "Processing current number of iteration : 33\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 13.348836898803711\n",
      "------------------------------------\n",
      "Processing current number of iteration : 34\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 10.928243398666382\n",
      "------------------------------------\n",
      "Processing current number of iteration : 35\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 15.501365661621094\n",
      "------------------------------------\n",
      "Processing current number of iteration : 36\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 13.732551097869873\n",
      "------------------------------------\n",
      "Processing current number of iteration : 37\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 10.476190090179443\n",
      "------------------------------------\n",
      "Processing current number of iteration : 38\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 13.303272485733032\n",
      "------------------------------------\n",
      "Processing current number of iteration : 39\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.861035823822021\n",
      "------------------------------------\n",
      "Processing current number of iteration : 40\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 14.618011236190796\n",
      "------------------------------------\n",
      "Processing current number of iteration : 41\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 12.960896730422974\n",
      "------------------------------------\n",
      "Processing current number of iteration : 42\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.726016521453857\n",
      "------------------------------------\n",
      "Processing current number of iteration : 43\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "Duration (seconds): 16.068320512771606\n",
      "------------------------------------\n",
      "Processing current number of iteration : 44\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 13.628013849258423\n",
      "------------------------------------\n",
      "Processing current number of iteration : 45\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 10.550036430358887\n",
      "------------------------------------\n",
      "Processing current number of iteration : 46\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 11.260043859481812\n",
      "------------------------------------\n",
      "Processing current number of iteration : 47\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.452715873718262\n",
      "------------------------------------\n",
      "Processing current number of iteration : 48\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "Duration (seconds): 13.29700756072998\n",
      "------------------------------------\n",
      "Processing current number of iteration : 49\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.115644693374634\n",
      "------------------------------------\n",
      "Processing current number of iteration : 50\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 12.263132333755493\n",
      "Finished - 50 times.\n",
      "And the list of mean squared errors : [136.61739677637095, 101.83409837886461, 79.99128779421888, 68.49246809998301, 61.233055251274656, 56.573654186465916, 53.12357857211978, 51.07991000452623, 49.64080101326969, 48.273053991217154, 47.37778941199373, 46.56721916590546, 46.146879848419616, 45.83320419773039, 45.69673919821435, 45.54325014103511, 45.54264002400197, 45.50529009232954, 45.23349562294849, 45.2367923284871, 45.23294057170442, 45.05557852508545, 45.104359745924036, 45.152975557275866, 44.9884436401576, 44.774109762279195, 44.476312641475694, 44.54052578599697, 44.456150976887706, 44.31780332576483, 44.182707357340135, 44.3366073390821, 44.32861594439947, 44.54838534083377, 44.30072330618767, 44.30113397480957, 44.20798046979947, 44.173351445657815, 44.34119273309544, 44.12127685904428, 44.172665441812235, 44.439698883582615, 44.1123915662477, 44.49142143449347, 44.190647235700055, 44.114697772107554, 43.95160596256964, 44.07377619587559, 43.90467742964418, 43.95030079310468]\n",
      "------------------------------------------------------------------------\n",
      "The mean and the standard deviation of the mean squared errors are: 49.96 and 15.96, respectively\n"
     ]
    }
   ],
   "source": [
    "max_iteration = 50\n",
    "epochs = 100\n",
    "verbose = 0\n",
    "\n",
    "# Get the compiled model\n",
    "model = build_model_with_one_hidden_layer(num_of_features=num_of_features)\n",
    "\n",
    "mean_mse, std_mse = get_mean_and_std_of_mse(df_predictors_norm, \n",
    "                                            df_target, \n",
    "                                            model, \n",
    "                                            max_iteration=max_iteration, \n",
    "                                            epochs=epochs, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35e2a65",
   "metadata": {},
   "source": [
    "## Report the mean and the standard deviation of the mean squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ddc02bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normalized-1 Hidden Layers(100 epochs)</td>\n",
       "      <td>49.96</td>\n",
       "      <td>15.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Experiment  Mean MSE  Std Deviation MSE\n",
       "0  Normalized-1 Hidden Layers(100 epochs)     49.96              15.96"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_experiment = \"Normalized-1 Hidden Layers(100 epochs)\"\n",
    "\n",
    "# Report the mean and the standard deviation of the mean squared errors\n",
    "df_result_baseline = get_report(name_of_experiment, mean_mse, std_mse)\n",
    "df_result_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dee8241d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline-Raw (50 epochs)</td>\n",
       "      <td>60.90</td>\n",
       "      <td>31.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normalized-1 Hidden Layers(50 epochs)</td>\n",
       "      <td>48.24</td>\n",
       "      <td>36.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normalized-1 Hidden Layers(100 epochs)</td>\n",
       "      <td>49.96</td>\n",
       "      <td>15.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Experiment  Mean MSE  Std Deviation MSE\n",
       "0                Baseline-Raw (50 epochs)     60.90              31.15\n",
       "1   Normalized-1 Hidden Layers(50 epochs)     48.24              36.87\n",
       "2  Normalized-1 Hidden Layers(100 epochs)     49.96              15.96"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat baseline dataframe into result\n",
    "df_mse_and_rmse = pd.concat([df_mse_and_rmse, df_result_baseline], axis=0)\n",
    "\n",
    "# Review the result dataframe\n",
    "df_mse_and_rmse.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d3136",
   "metadata": {},
   "source": [
    "# D. Increase the number of hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860429d1",
   "metadata": {},
   "source": [
    "Repeat part B but use a neural network with the following instead:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13344606",
   "metadata": {},
   "source": [
    "Three hidden layers, each of 10 nodes and ReLU activation function.\n",
    "How does the mean of the mean squared errors compare to that from Step B?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa4200",
   "metadata": {},
   "source": [
    "## Building and Training with the model after normalizing the data with 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a823d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Processing current number of iteration : 1\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 1s 8ms/step\n",
      "Duration (seconds): 11.61649227142334\n",
      "------------------------------------\n",
      "Processing current number of iteration : 2\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 7.670273542404175\n",
      "------------------------------------\n",
      "Processing current number of iteration : 3\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 7.561892509460449\n",
      "------------------------------------\n",
      "Processing current number of iteration : 4\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 8.30018663406372\n",
      "------------------------------------\n",
      "Processing current number of iteration : 5\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 8.256969213485718\n",
      "------------------------------------\n",
      "Processing current number of iteration : 6\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.5975000858306885\n",
      "------------------------------------\n",
      "Processing current number of iteration : 7\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 6.546707391738892\n",
      "------------------------------------\n",
      "Processing current number of iteration : 8\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.380032300949097\n",
      "------------------------------------\n",
      "Processing current number of iteration : 9\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.797653675079346\n",
      "------------------------------------\n",
      "Processing current number of iteration : 10\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.199005603790283\n",
      "------------------------------------\n",
      "Processing current number of iteration : 11\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 7.487900733947754\n",
      "------------------------------------\n",
      "Processing current number of iteration : 12\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "Duration (seconds): 7.097075462341309\n",
      "------------------------------------\n",
      "Processing current number of iteration : 13\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.977964639663696\n",
      "------------------------------------\n",
      "Processing current number of iteration : 14\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 8ms/step\n",
      "Duration (seconds): 7.168978214263916\n",
      "------------------------------------\n",
      "Processing current number of iteration : 15\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.652643918991089\n",
      "------------------------------------\n",
      "Processing current number of iteration : 16\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 6.689004898071289\n",
      "------------------------------------\n",
      "Processing current number of iteration : 17\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 6.9620044231414795\n",
      "------------------------------------\n",
      "Processing current number of iteration : 18\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.016242504119873\n",
      "------------------------------------\n",
      "Processing current number of iteration : 19\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.1134233474731445\n",
      "------------------------------------\n",
      "Processing current number of iteration : 20\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.981004953384399\n",
      "------------------------------------\n",
      "Processing current number of iteration : 21\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 6.540450811386108\n",
      "------------------------------------\n",
      "Processing current number of iteration : 22\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 6.504690408706665\n",
      "------------------------------------\n",
      "Processing current number of iteration : 23\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.08642578125\n",
      "------------------------------------\n",
      "Processing current number of iteration : 24\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.682135581970215\n",
      "------------------------------------\n",
      "Processing current number of iteration : 25\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.379002809524536\n",
      "------------------------------------\n",
      "Processing current number of iteration : 26\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 10.92292046546936\n",
      "------------------------------------\n",
      "Processing current number of iteration : 27\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.626136064529419\n",
      "------------------------------------\n",
      "Processing current number of iteration : 28\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.344919204711914\n",
      "------------------------------------\n",
      "Processing current number of iteration : 29\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.1280295848846436\n",
      "------------------------------------\n",
      "Processing current number of iteration : 30\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.1558918952941895\n",
      "------------------------------------\n",
      "Processing current number of iteration : 31\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.267900705337524\n",
      "------------------------------------\n",
      "Processing current number of iteration : 32\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.137114524841309\n",
      "------------------------------------\n",
      "Processing current number of iteration : 33\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.312011957168579\n",
      "------------------------------------\n",
      "Processing current number of iteration : 34\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 7.061507940292358\n",
      "------------------------------------\n",
      "Processing current number of iteration : 35\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.062230587005615\n",
      "------------------------------------\n",
      "Processing current number of iteration : 36\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.6685566902160645\n",
      "------------------------------------\n",
      "Processing current number of iteration : 37\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.88934326171875\n",
      "------------------------------------\n",
      "Processing current number of iteration : 38\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.861005544662476\n",
      "------------------------------------\n",
      "Processing current number of iteration : 39\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.810977935791016\n",
      "------------------------------------\n",
      "Processing current number of iteration : 40\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.914165258407593\n",
      "------------------------------------\n",
      "Processing current number of iteration : 41\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 9ms/step\n",
      "Duration (seconds): 7.2030065059661865\n",
      "------------------------------------\n",
      "Processing current number of iteration : 42\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.859899044036865\n",
      "------------------------------------\n",
      "Processing current number of iteration : 43\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.66928243637085\n",
      "------------------------------------\n",
      "Processing current number of iteration : 44\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 6.776800870895386\n",
      "------------------------------------\n",
      "Processing current number of iteration : 45\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 7.324483156204224\n",
      "------------------------------------\n",
      "Processing current number of iteration : 46\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.691006183624268\n",
      "------------------------------------\n",
      "Processing current number of iteration : 47\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 6.4589762687683105\n",
      "------------------------------------\n",
      "Processing current number of iteration : 48\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 7ms/step\n",
      "Duration (seconds): 7.688033819198608\n",
      "------------------------------------\n",
      "Processing current number of iteration : 49\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 6ms/step\n",
      "Duration (seconds): 7.034001111984253\n",
      "------------------------------------\n",
      "Processing current number of iteration : 50\n",
      "Training set:  (721, 8) (721, 1)\n",
      "Testing set:  (309, 8) (309, 1)\n",
      "10/10 [==============================] - 0s 5ms/step\n",
      "Duration (seconds): 6.817149877548218\n",
      "Finished - 50 times.\n",
      "And the list of mean squared errors : [121.45416315789359, 66.65401775349103, 48.82078977222529, 45.93270913557884, 44.21209309521764, 43.924255599367754, 43.439480359373846, 42.71995204536698, 41.67913809168703, 41.736962244614496, 40.282385979690645, 38.41916720817989, 38.379824286473735, 37.53327284203348, 37.13096631245348, 37.45258693698134, 37.41272714247411, 36.73547140343042, 36.44271773007923, 37.13178163858159, 36.356936328573475, 36.288042700909614, 36.64718403192845, 36.05214104897581, 37.29547474868194, 36.27263104227652, 36.23601608392176, 36.412401042726124, 35.86667437967477, 36.01700879826474, 37.263647119694674, 36.212850793115734, 36.19385048881587, 36.02681121680845, 35.842800355743265, 35.87468201375068, 35.29431232382965, 35.5004373226288, 35.945527836028, 34.94158568385174, 34.88736429565511, 35.2731847961347, 35.617359207559495, 34.99804102299501, 35.71806286336672, 36.792924649992614, 35.091997334090294, 35.30375478334139, 35.09305421960134, 35.30594321727049]\n",
      "------------------------------------------------------------------------\n",
      "The mean and the standard deviation of the mean squared errors are: 39.88 and 12.73, respectively\n"
     ]
    }
   ],
   "source": [
    "max_iteration = 50\n",
    "epochs = 50\n",
    "verbose = 0\n",
    "\n",
    "# Get the compiled model\n",
    "model = build_model_with_three_hidden_layers(num_of_features=num_of_features)\n",
    "\n",
    "mean_mse, std_mse = get_mean_and_std_of_mse(df_predictors_norm, \n",
    "                                            df_target, \n",
    "                                            model, \n",
    "                                            max_iteration=max_iteration, \n",
    "                                            epochs=epochs, \n",
    "                                            verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c2e2c",
   "metadata": {},
   "source": [
    "## Report the mean and the standard deviation of the mean squared errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58eec4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normalized-3 Hidden Layers(50 epochs)</td>\n",
       "      <td>39.88</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Experiment  Mean MSE  Std Deviation MSE\n",
       "0  Normalized-3 Hidden Layers(50 epochs)     39.88              12.73"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_of_experiment = \"Normalized-3 Hidden Layers(50 epochs)\"\n",
    "\n",
    "# Report the mean and the standard deviation of the mean squared errors\n",
    "df_result_baseline = get_report(name_of_experiment, mean_mse, std_mse)\n",
    "df_result_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "124dcab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Mean MSE</th>\n",
       "      <th>Std Deviation MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline-Raw (50 epochs)</td>\n",
       "      <td>60.90</td>\n",
       "      <td>31.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normalized-1 Hidden Layers(50 epochs)</td>\n",
       "      <td>48.24</td>\n",
       "      <td>36.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normalized-1 Hidden Layers(100 epochs)</td>\n",
       "      <td>49.96</td>\n",
       "      <td>15.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normalized-3 Hidden Layers(50 epochs)</td>\n",
       "      <td>39.88</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Experiment  Mean MSE  Std Deviation MSE\n",
       "0                Baseline-Raw (50 epochs)     60.90              31.15\n",
       "1   Normalized-1 Hidden Layers(50 epochs)     48.24              36.87\n",
       "2  Normalized-1 Hidden Layers(100 epochs)     49.96              15.96\n",
       "3   Normalized-3 Hidden Layers(50 epochs)     39.88              12.73"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat baseline dataframe into result\n",
    "df_mse_and_rmse = pd.concat([df_mse_and_rmse, df_result_baseline], axis=0)\n",
    "\n",
    "# Review the result dataframe\n",
    "df_mse_and_rmse.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce36e65",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8072bd",
   "metadata": {},
   "source": [
    "As you see, the mean squared error (MSE) tells us how close a regression model is to our testing set. And the standard deviation of residuals is used to estimate the disagreement between a set of data and a linear regression model.\n",
    "\n",
    "Thus, according to the mean squared error, the smaller score, the closer we are finding the regression line of best fit.\n",
    "\n",
    "Indeed, the model (D-Normalized-3 Hidden Layers(50 epochs)), which is trained with three hidden layers, each of 10 nodes and ReLU activation function, is the best one. Because its mean of the mean squared errors is 34.17. Moreover, its error is lower than about 16 and 17 when comparing with the trained model applying one hidden layer with 50 epochs and 100 epochs.\n",
    "\n",
    "Also, when comparing to mean of the MSEs of baseline model, the MSE of model (D) is lower, about 35.\n",
    "\n",
    "However, it is interesting that the mean of the MSEs of baseline model (B-Normalized-1 Hidden Layers(50 epochs)) is lower about 1 than the mean the MSEs of model (C-Normalized-1 Hidden Layers(100 epochs)) which is trained by the normalized data and the same configuration of model, but model (C) did 100 epochs.\n",
    "\n",
    "In conclusion, in order to get the better result, we could apply several techniques to tune the model such as normalizing the input data, improving the number of epochs or the number of hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc646cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
